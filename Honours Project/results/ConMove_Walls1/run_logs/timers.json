{
    "name": "root",
    "gauges": {
        "Movement.Policy.Entropy.mean": {
            "value": 1.2553927898406982,
            "min": 1.2553927898406982,
            "max": 1.3265774250030518,
            "count": 20
        },
        "Movement.Policy.Entropy.sum": {
            "value": 6427.611328125,
            "min": 6013.76416015625,
            "max": 7293.5390625,
            "count": 20
        },
        "Movement.Environment.EpisodeLength.mean": {
            "value": 399.0,
            "min": 47.801980198019805,
            "max": 399.0,
            "count": 20
        },
        "Movement.Environment.EpisodeLength.sum": {
            "value": 4788.0,
            "min": 2840.0,
            "max": 7415.0,
            "count": 20
        },
        "Movement.Step.mean": {
            "value": 99951.0,
            "min": 4993.0,
            "max": 99951.0,
            "count": 20
        },
        "Movement.Step.sum": {
            "value": 99951.0,
            "min": 4993.0,
            "max": 99951.0,
            "count": 20
        },
        "Movement.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.17691348493099213,
            "min": -1.1832283735275269,
            "max": -0.1545722484588623,
            "count": 20
        },
        "Movement.Policy.ExtrinsicValueEstimate.sum": {
            "value": -15.391472816467285,
            "min": -143.17063903808594,
            "max": -13.756930351257324,
            "count": 20
        },
        "Movement.Policy.CuriosityValueEstimate.mean": {
            "value": 0.2552611231803894,
            "min": 0.14314204454421997,
            "max": 0.753231406211853,
            "count": 20
        },
        "Movement.Policy.CuriosityValueEstimate.sum": {
            "value": 22.207717895507812,
            "min": 12.596500396728516,
            "max": 91.14099884033203,
            "count": 20
        },
        "Movement.Environment.CumulativeReward.mean": {
            "value": -0.6446250441173712,
            "min": -1.6144818406213413,
            "max": -0.6170357667974063,
            "count": 20
        },
        "Movement.Environment.CumulativeReward.sum": {
            "value": -7.735500529408455,
            "min": -159.2150018364191,
            "max": -7.735500529408455,
            "count": 20
        },
        "Movement.Policy.ExtrinsicReward.mean": {
            "value": -0.6446250441173712,
            "min": -1.6144818406213413,
            "max": -0.6170357667974063,
            "count": 20
        },
        "Movement.Policy.ExtrinsicReward.sum": {
            "value": -7.735500529408455,
            "min": -159.2150018364191,
            "max": -7.735500529408455,
            "count": 20
        },
        "Movement.Policy.CuriosityReward.mean": {
            "value": 1.3520161238654207,
            "min": 0.15871333482283273,
            "max": 1.3520161238654207,
            "count": 20
        },
        "Movement.Policy.CuriosityReward.sum": {
            "value": 16.224193486385047,
            "min": 6.312824456952512,
            "max": 26.509244721732102,
            "count": 20
        },
        "Movement.Losses.PolicyLoss.mean": {
            "value": 0.24644326176541628,
            "min": 0.2307515465467851,
            "max": 0.25421169487998047,
            "count": 20
        },
        "Movement.Losses.PolicyLoss.sum": {
            "value": 8.132627638258738,
            "min": 8.076304129137478,
            "max": 9.599840489708116,
            "count": 20
        },
        "Movement.Losses.ValueLoss.mean": {
            "value": 0.012512014442993576,
            "min": 0.002430547293216097,
            "max": 0.019175219760612892,
            "count": 20
        },
        "Movement.Losses.ValueLoss.sum": {
            "value": 0.41289647661878803,
            "min": 0.0826386079693473,
            "max": 0.6903079113820642,
            "count": 20
        },
        "Movement.Policy.LearningRate.mean": {
            "value": 7.319461196575758e-06,
            "min": 7.319461196575758e-06,
            "max": 0.00029216950261016665,
            "count": 20
        },
        "Movement.Policy.LearningRate.sum": {
            "value": 0.00024154221948700003,
            "min": 0.00024154221948700003,
            "max": 0.010820223293258999,
            "count": 20
        },
        "Movement.Policy.Epsilon.mean": {
            "value": 0.10243978787878788,
            "min": 0.10243978787878788,
            "max": 0.19738983333333338,
            "count": 20
        },
        "Movement.Policy.Epsilon.sum": {
            "value": 3.380513,
            "min": 3.380513,
            "max": 7.506741000000001,
            "count": 20
        },
        "Movement.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005000000000000001,
            "count": 20
        },
        "Movement.Policy.Beta.sum": {
            "value": 0.0165,
            "min": 0.0165,
            "max": 0.019500000000000003,
            "count": 20
        },
        "Movement.Losses.CuriosityForwardLoss.mean": {
            "value": 0.11915527331169491,
            "min": 0.05409686539008022,
            "max": 0.2189824207890373,
            "count": 20
        },
        "Movement.Losses.CuriosityForwardLoss.sum": {
            "value": 3.932124019285932,
            "min": 1.8392934232627274,
            "max": 7.883367148405342,
            "count": 20
        },
        "Movement.Losses.CuriosityInverseLoss.mean": {
            "value": 0.47662415938608055,
            "min": 0.3130588518353004,
            "max": 2.279829168691034,
            "count": 20
        },
        "Movement.Losses.CuriosityInverseLoss.sum": {
            "value": 15.728597259740658,
            "min": 10.644000962400215,
            "max": 82.07385007287722,
            "count": 20
        },
        "Movement.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "Movement.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1683644899",
        "python_version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]",
        "command_line_arguments": "D:\\University\\Honours\\Testing\\MLAgents Testing2\\venv\\Scripts\\mlagents-learn config/Movement.yaml --initialize-from=ConMove1 --run-id=ConMove_Walls1",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1683645296"
    },
    "total": 396.7358339,
    "count": 1,
    "self": 0.006170100000019829,
    "children": {
        "run_training.setup": {
            "total": 0.06508229999999993,
            "count": 1,
            "self": 0.06508229999999993
        },
        "TrainerController.start_learning": {
            "total": 396.6645815,
            "count": 1,
            "self": 0.08374479999974938,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.000315899999999,
                    "count": 1,
                    "self": 9.000315899999999
                },
                "TrainerController.advance": {
                    "total": 387.52439730000026,
                    "count": 5549,
                    "self": 0.07995079999790278,
                    "children": {
                        "env_step": {
                            "total": 45.18952140000136,
                            "count": 5549,
                            "self": 38.890256100003036,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 6.2533796999984546,
                                    "count": 5549,
                                    "self": 0.2635374999966533,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 5.989842200001801,
                                            "count": 5035,
                                            "self": 2.8111347000005242,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3.178707500001277,
                                                    "count": 5035,
                                                    "self": 3.178707500001277
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.04588559999987041,
                                    "count": 5549,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 388.3867518999982,
                                            "count": 5549,
                                            "is_parallel": true,
                                            "self": 354.5515206999982,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003560999999994152,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00010379999999976519,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00025229999999965,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00025229999999965
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 33.8348751,
                                                    "count": 5549,
                                                    "is_parallel": true,
                                                    "self": 0.6278717999954893,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.9409112000013451,
                                                            "count": 5549,
                                                            "is_parallel": true,
                                                            "self": 0.9409112000013451
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 30.58910080000281,
                                                            "count": 5549,
                                                            "is_parallel": true,
                                                            "self": 30.58910080000281
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1.6769913000003527,
                                                            "count": 5549,
                                                            "is_parallel": true,
                                                            "self": 0.47380990000133494,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.2031813999990177,
                                                                    "count": 11098,
                                                                    "is_parallel": true,
                                                                    "self": 1.2031813999990177
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 342.254925100001,
                            "count": 5549,
                            "self": 0.15167059999930643,
                            "children": {
                                "process_trajectory": {
                                    "total": 8.282229600000344,
                                    "count": 5549,
                                    "self": 8.282229600000344
                                },
                                "_update_policy": {
                                    "total": 333.82102490000136,
                                    "count": 722,
                                    "self": 13.36514499999862,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 320.45587990000274,
                                            "count": 28722,
                                            "self": 320.45587990000274
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000000212225132e-07,
                    "count": 1,
                    "self": 6.000000212225132e-07
                },
                "TrainerController._save_models": {
                    "total": 0.056122899999991205,
                    "count": 1,
                    "self": 0.010794799999985116,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04532810000000609,
                            "count": 1,
                            "self": 0.04532810000000609
                        }
                    }
                }
            }
        }
    }
}