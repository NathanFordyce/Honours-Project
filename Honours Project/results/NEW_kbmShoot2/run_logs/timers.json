{
    "name": "root",
    "gauges": {
        "Shooting.Policy.Entropy.mean": {
            "value": 1.6990433931350708,
            "min": 1.6969592571258545,
            "max": 2.528017044067383,
            "count": 10
        },
        "Shooting.Policy.Entropy.sum": {
            "value": 16990.43359375,
            "min": 16990.43359375,
            "max": 25431.8515625,
            "count": 10
        },
        "Shooting.Environment.EpisodeLength.mean": {
            "value": 9.014028056112224,
            "min": 8.878817733990148,
            "max": 9.343685300207039,
            "count": 10
        },
        "Shooting.Environment.EpisodeLength.sum": {
            "value": 8996.0,
            "min": 8996.0,
            "max": 9026.0,
            "count": 10
        },
        "Shooting.Step.mean": {
            "value": 99995.0,
            "min": 9997.0,
            "max": 99995.0,
            "count": 10
        },
        "Shooting.Step.sum": {
            "value": 99995.0,
            "min": 9997.0,
            "max": 99995.0,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.9132106900215149,
            "min": 0.7530132532119751,
            "max": 0.9132106900215149,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicValueEstimate.sum": {
            "value": 912.2974853515625,
            "min": 762.0494384765625,
            "max": 912.2974853515625,
            "count": 10
        },
        "Shooting.Policy.CuriosityValueEstimate.mean": {
            "value": 3.4228596687316895,
            "min": 1.8895403146743774,
            "max": 3.450117826461792,
            "count": 10
        },
        "Shooting.Policy.CuriosityValueEstimate.sum": {
            "value": 3419.436767578125,
            "min": 1912.21484375,
            "max": 3445.022216796875,
            "count": 10
        },
        "Shooting.Environment.CumulativeReward.mean": {
            "value": 0.95995995995996,
            "min": 0.7549407114624506,
            "max": 0.95995995995996,
            "count": 10
        },
        "Shooting.Environment.CumulativeReward.sum": {
            "value": 959.0,
            "min": 764.0,
            "max": 959.0,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicReward.mean": {
            "value": 0.95995995995996,
            "min": 0.7549407114624506,
            "max": 0.95995995995996,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicReward.sum": {
            "value": 959.0,
            "min": 764.0,
            "max": 959.0,
            "count": 10
        },
        "Shooting.Policy.CuriosityReward.mean": {
            "value": 0.0437066546259998,
            "min": 0.0433314660608858,
            "max": 0.059061861924620956,
            "count": 10
        },
        "Shooting.Policy.CuriosityReward.sum": {
            "value": 43.6629479713738,
            "min": 43.24480312876403,
            "max": 59.77060426771641,
            "count": 10
        },
        "Shooting.Losses.PolicyLoss.mean": {
            "value": 0.23727884334606397,
            "min": 0.23723901774045575,
            "max": 0.24730882983130745,
            "count": 10
        },
        "Shooting.Losses.PolicyLoss.sum": {
            "value": 19.931422841069374,
            "min": 15.308611648315077,
            "max": 20.860568360854252,
            "count": 10
        },
        "Shooting.Losses.ValueLoss.mean": {
            "value": 0.03287540401229712,
            "min": 0.03206021135102796,
            "max": 0.13728120393173449,
            "count": 10
        },
        "Shooting.Losses.ValueLoss.sum": {
            "value": 2.761533937032958,
            "min": 2.693057753486349,
            "max": 9.386906937169893,
            "count": 10
        },
        "Shooting.Policy.LearningRate.mean": {
            "value": 1.5210344929916666e-05,
            "min": 1.5210344929916666e-05,
            "max": 0.0002837363280018709,
            "count": 10
        },
        "Shooting.Policy.LearningRate.sum": {
            "value": 0.001277668974113,
            "min": 0.001277668974113,
            "max": 0.021921274292909,
            "count": 10
        },
        "Shooting.Policy.Epsilon.mean": {
            "value": 0.10507008333333336,
            "min": 0.10507008333333336,
            "max": 0.19457877419354838,
            "count": 10
        },
        "Shooting.Policy.Epsilon.sum": {
            "value": 8.825887000000002,
            "min": 8.825887000000002,
            "max": 15.907091,
            "count": 10
        },
        "Shooting.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005,
            "max": 0.0005000000000000001,
            "count": 10
        },
        "Shooting.Policy.Beta.sum": {
            "value": 0.04200000000000001,
            "min": 0.031000000000000003,
            "max": 0.04300000000000001,
            "count": 10
        },
        "Shooting.Losses.CuriosityForwardLoss.mean": {
            "value": 0.08178036806110892,
            "min": 0.08126659420983535,
            "max": 0.11685619120372778,
            "count": 10
        },
        "Shooting.Losses.CuriosityForwardLoss.sum": {
            "value": 6.869550917133149,
            "min": 6.82639391362617,
            "max": 9.070109047305243,
            "count": 10
        },
        "Shooting.Losses.CuriosityInverseLoss.mean": {
            "value": 0.610632970680219,
            "min": 0.610632970680219,
            "max": 1.2518359494769398,
            "count": 10
        },
        "Shooting.Losses.CuriosityInverseLoss.sum": {
            "value": 51.293169537138404,
            "min": 51.293169537138404,
            "max": 107.65789165501681,
            "count": 10
        },
        "Shooting.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "Shooting.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1681477350",
        "python_version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]",
        "command_line_arguments": "D:\\University\\Honours\\Testing\\MLAgents Testing2\\venv\\Scripts\\mlagents-learn config/Shooting.yaml --initialize-from=NEW_kbmShoot1 --run-id=NEW_kbmShoot2",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1681477994"
    },
    "total": 644.263971,
    "count": 1,
    "self": 0.006115399999998772,
    "children": {
        "run_training.setup": {
            "total": 0.06273669999999998,
            "count": 1,
            "self": 0.06273669999999998
        },
        "TrainerController.start_learning": {
            "total": 644.1951189,
            "count": 1,
            "self": 0.15046249999682004,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.624248000000001,
                    "count": 1,
                    "self": 4.624248000000001
                },
                "TrainerController.advance": {
                    "total": 639.3266640000032,
                    "count": 9117,
                    "self": 0.1293987000050265,
                    "children": {
                        "env_step": {
                            "total": 84.65387690000266,
                            "count": 9117,
                            "self": 69.00115070000533,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 15.575683699999281,
                                    "count": 9117,
                                    "self": 0.2609279999998293,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 15.314755699999452,
                                            "count": 5005,
                                            "self": 6.084822800001575,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 9.229932899997877,
                                                    "count": 5005,
                                                    "self": 9.229932899997877
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.07704249999804702,
                                    "count": 9117,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 640.1376356000025,
                                            "count": 9117,
                                            "is_parallel": true,
                                            "self": 578.7739133999964,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006040999999998853,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00019240000000042556,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0004116999999994597,
                                                            "count": 6,
                                                            "is_parallel": true,
                                                            "self": 0.0004116999999994597
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 61.36311810000605,
                                                    "count": 9117,
                                                    "is_parallel": true,
                                                    "self": 1.2810557000002305,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 1.0797479000039525,
                                                            "count": 9117,
                                                            "is_parallel": true,
                                                            "self": 1.0797479000039525
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 55.25213940000046,
                                                            "count": 9117,
                                                            "is_parallel": true,
                                                            "self": 55.25213940000046
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 3.7501751000014094,
                                                            "count": 9117,
                                                            "is_parallel": true,
                                                            "self": 1.127598099998539,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.6225770000028703,
                                                                    "count": 54702,
                                                                    "is_parallel": true,
                                                                    "self": 2.6225770000028703
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 554.5433883999956,
                            "count": 9117,
                            "self": 0.18328729999666393,
                            "children": {
                                "process_trajectory": {
                                    "total": 42.06097069999891,
                                    "count": 9117,
                                    "self": 42.06097069999891
                                },
                                "_update_policy": {
                                    "total": 512.2991304,
                                    "count": 822,
                                    "self": 15.349524000005204,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 496.94960639999476,
                                            "count": 29769,
                                            "self": 496.94960639999476
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000000212225132e-07,
                    "count": 1,
                    "self": 6.000000212225132e-07
                },
                "TrainerController._save_models": {
                    "total": 0.09374379999997018,
                    "count": 1,
                    "self": 0.004659700000047451,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08908409999992273,
                            "count": 1,
                            "self": 0.08908409999992273
                        }
                    }
                }
            }
        }
    }
}