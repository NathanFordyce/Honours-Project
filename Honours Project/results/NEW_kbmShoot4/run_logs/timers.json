{
    "name": "root",
    "gauges": {
        "Shooting.Policy.Entropy.mean": {
            "value": 1.9447619915008545,
            "min": 1.4904314279556274,
            "max": 1.9728032350540161,
            "count": 10
        },
        "Shooting.Policy.Entropy.sum": {
            "value": 19486.515625,
            "min": 15381.251953125,
            "max": 19846.400390625,
            "count": 10
        },
        "Shooting.Environment.EpisodeLength.mean": {
            "value": 36.16541353383459,
            "min": 25.798387096774192,
            "max": 40.00413223140496,
            "count": 10
        },
        "Shooting.Environment.EpisodeLength.sum": {
            "value": 9620.0,
            "min": 9597.0,
            "max": 9850.0,
            "count": 10
        },
        "Shooting.Step.mean": {
            "value": 99995.0,
            "min": 9965.0,
            "max": 99995.0,
            "count": 10
        },
        "Shooting.Step.sum": {
            "value": 99995.0,
            "min": 9965.0,
            "max": 99995.0,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.8251047134399414,
            "min": -0.8717703223228455,
            "max": -0.8198258876800537,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicValueEstimate.sum": {
            "value": -240.93057250976562,
            "min": -324.28546142578125,
            "max": -225.45211791992188,
            "count": 10
        },
        "Shooting.Policy.CuriosityValueEstimate.mean": {
            "value": 0.7253224849700928,
            "min": 0.6459366083145142,
            "max": 1.4810559749603271,
            "count": 10
        },
        "Shooting.Policy.CuriosityValueEstimate.sum": {
            "value": 211.79415893554688,
            "min": 177.632568359375,
            "max": 545.8365478515625,
            "count": 10
        },
        "Shooting.Environment.CumulativeReward.mean": {
            "value": -1.0,
            "min": -1.0,
            "max": -1.0,
            "count": 10
        },
        "Shooting.Environment.CumulativeReward.sum": {
            "value": -266.0,
            "min": -372.0,
            "max": -242.0,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicReward.mean": {
            "value": -1.0,
            "min": -1.0,
            "max": -1.0,
            "count": 10
        },
        "Shooting.Policy.ExtrinsicReward.sum": {
            "value": -266.0,
            "min": -372.0,
            "max": -242.0,
            "count": 10
        },
        "Shooting.Policy.CuriosityReward.mean": {
            "value": 0.10558796916734707,
            "min": 0.06671177770336528,
            "max": 0.12344465687224442,
            "count": 10
        },
        "Shooting.Policy.CuriosityReward.sum": {
            "value": 28.08639979851432,
            "min": 22.148310197517276,
            "max": 30.59463081578724,
            "count": 10
        },
        "Shooting.Losses.PolicyLoss.mean": {
            "value": 0.24540683644374614,
            "min": 0.23954935041970715,
            "max": 0.2508653890969395,
            "count": 10
        },
        "Shooting.Losses.PolicyLoss.sum": {
            "value": 20.123360588387182,
            "min": 19.003639759188456,
            "max": 20.821827295045978,
            "count": 10
        },
        "Shooting.Losses.ValueLoss.mean": {
            "value": 0.004678245844697469,
            "min": 0.001460825254871525,
            "max": 0.004678245844697469,
            "count": 10
        },
        "Shooting.Losses.ValueLoss.sum": {
            "value": 0.3836161592651925,
            "min": 0.12124849615433657,
            "max": 0.3836161592651925,
            "count": 10
        },
        "Shooting.Policy.LearningRate.mean": {
            "value": 1.4970790131719512e-05,
            "min": 1.4970790131719512e-05,
            "max": 0.00028518117567131703,
            "count": 10
        },
        "Shooting.Policy.LearningRate.sum": {
            "value": 0.001227604790801,
            "min": 0.001227604790801,
            "max": 0.023384856405047998,
            "count": 10
        },
        "Shooting.Policy.Epsilon.mean": {
            "value": 0.10499023170731708,
            "min": 0.10499023170731708,
            "max": 0.19506039024390245,
            "count": 10
        },
        "Shooting.Policy.Epsilon.sum": {
            "value": 8.609199,
            "min": 8.609199,
            "max": 15.994952000000001,
            "count": 10
        },
        "Shooting.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005000000000000001,
            "max": 0.0005000000000000001,
            "count": 10
        },
        "Shooting.Policy.Beta.sum": {
            "value": 0.04100000000000001,
            "min": 0.03900000000000001,
            "max": 0.04150000000000001,
            "count": 10
        },
        "Shooting.Losses.CuriosityForwardLoss.mean": {
            "value": 0.05337078645697914,
            "min": 0.0422579763148691,
            "max": 0.057622854400436525,
            "count": 10
        },
        "Shooting.Losses.CuriosityForwardLoss.sum": {
            "value": 4.376404489472289,
            "min": 3.4651540578192663,
            "max": 4.5522054976344855,
            "count": 10
        },
        "Shooting.Losses.CuriosityInverseLoss.mean": {
            "value": 1.3618605533274792,
            "min": 1.1239237694850128,
            "max": 1.4430728480294794,
            "count": 10
        },
        "Shooting.Losses.CuriosityInverseLoss.sum": {
            "value": 111.6725653728533,
            "min": 92.16174909777105,
            "max": 115.44582784235836,
            "count": 10
        },
        "Shooting.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "Shooting.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1681483660",
        "python_version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]",
        "command_line_arguments": "D:\\University\\Honours\\Testing\\MLAgents Testing2\\venv\\Scripts\\mlagents-learn config/Shooting.yaml --initialize-from=NEW_kbmShoot3 --run-id=NEW_kbmShoot4",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1681484220"
    },
    "total": 559.25089,
    "count": 1,
    "self": 0.0065690000001268345,
    "children": {
        "run_training.setup": {
            "total": 0.06298160000000008,
            "count": 1,
            "self": 0.06298160000000008
        },
        "TrainerController.start_learning": {
            "total": 559.1813394,
            "count": 1,
            "self": 0.11246099999834769,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.5197788,
                    "count": 1,
                    "self": 4.5197788
                },
                "TrainerController.advance": {
                    "total": 554.4687230000017,
                    "count": 7462,
                    "self": 0.0976711000045043,
                    "children": {
                        "env_step": {
                            "total": 74.4814939999988,
                            "count": 7462,
                            "self": 58.97173909999938,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 15.44895449999997,
                                    "count": 7462,
                                    "self": 0.23168999999793982,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 15.217264500002031,
                                            "count": 5023,
                                            "self": 6.050064400000764,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 9.167200100001267,
                                                    "count": 5023,
                                                    "self": 9.167200100001267
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.06080039999944997,
                                    "count": 7462,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 555.2795319000004,
                                            "count": 7462,
                                            "is_parallel": true,
                                            "self": 502.65854180000076,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006838000000000122,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00019900000000028228,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0004847999999997299,
                                                            "count": 6,
                                                            "is_parallel": true,
                                                            "self": 0.0004847999999997299
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 52.62030629999965,
                                                    "count": 7462,
                                                    "is_parallel": true,
                                                    "self": 1.0773651000006481,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.9758638999983145,
                                                            "count": 7462,
                                                            "is_parallel": true,
                                                            "self": 0.9758638999983145
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 47.32378189999926,
                                                            "count": 7462,
                                                            "is_parallel": true,
                                                            "self": 47.32378189999926
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 3.243295400001422,
                                                            "count": 7462,
                                                            "is_parallel": true,
                                                            "self": 0.9635552000054899,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.279740199995932,
                                                                    "count": 44772,
                                                                    "is_parallel": true,
                                                                    "self": 2.279740199995932
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 479.88955789999835,
                            "count": 7462,
                            "self": 0.1842242999959467,
                            "children": {
                                "process_trajectory": {
                                    "total": 17.480045900002253,
                                    "count": 7462,
                                    "self": 17.480045900002253
                                },
                                "_update_policy": {
                                    "total": 462.22528770000014,
                                    "count": 812,
                                    "self": 14.431315200006622,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 447.7939724999935,
                                            "count": 28914,
                                            "self": 447.7939724999935
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.999999075356754e-07,
                    "count": 1,
                    "self": 5.999999075356754e-07
                },
                "TrainerController._save_models": {
                    "total": 0.08037600000000111,
                    "count": 1,
                    "self": 0.0068860000000086075,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.0734899999999925,
                            "count": 1,
                            "self": 0.0734899999999925
                        }
                    }
                }
            }
        }
    }
}