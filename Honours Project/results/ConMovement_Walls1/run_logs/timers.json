{
    "name": "root",
    "gauges": {
        "Movement.Policy.Entropy.mean": {
            "value": 1.3211702108383179,
            "min": 1.320011019706726,
            "max": 1.3680500984191895,
            "count": 20
        },
        "Movement.Policy.Entropy.sum": {
            "value": 6473.73388671875,
            "min": 6396.595703125,
            "max": 7414.83154296875,
            "count": 20
        },
        "Movement.Environment.EpisodeLength.mean": {
            "value": 270.0,
            "min": 132.11111111111111,
            "max": 399.0,
            "count": 20
        },
        "Movement.Environment.EpisodeLength.sum": {
            "value": 4320.0,
            "min": 3567.0,
            "max": 6277.0,
            "count": 20
        },
        "Movement.Step.mean": {
            "value": 99979.0,
            "min": 4996.0,
            "max": 99979.0,
            "count": 20
        },
        "Movement.Step.sum": {
            "value": 99979.0,
            "min": 4996.0,
            "max": 99979.0,
            "count": 20
        },
        "Movement.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.05910266190767288,
            "min": -0.47034305334091187,
            "max": 0.16462156176567078,
            "count": 20
        },
        "Movement.Policy.ExtrinsicValueEstimate.sum": {
            "value": -5.141931533813477,
            "min": -44.68259048461914,
            "max": 14.322075843811035,
            "count": 20
        },
        "Movement.Policy.CuriosityValueEstimate.mean": {
            "value": 0.35578033328056335,
            "min": 0.19199968874454498,
            "max": 0.41101253032684326,
            "count": 20
        },
        "Movement.Policy.CuriosityValueEstimate.sum": {
            "value": 30.95288848876953,
            "min": 16.31997299194336,
            "max": 36.580116271972656,
            "count": 20
        },
        "Movement.Environment.CumulativeReward.mean": {
            "value": -0.16249999776482582,
            "min": -0.8521739108406979,
            "max": 0.676923081278801,
            "count": 20
        },
        "Movement.Environment.CumulativeReward.sum": {
            "value": -2.599999964237213,
            "min": -28.0,
            "max": 8.800000056624413,
            "count": 20
        },
        "Movement.Policy.ExtrinsicReward.mean": {
            "value": -0.16249999776482582,
            "min": -0.8521739108406979,
            "max": 0.676923081278801,
            "count": 20
        },
        "Movement.Policy.ExtrinsicReward.sum": {
            "value": -2.599999964237213,
            "min": -28.0,
            "max": 8.800000056624413,
            "count": 20
        },
        "Movement.Policy.CuriosityReward.mean": {
            "value": 0.9586935536935925,
            "min": 0.3669581822430938,
            "max": 1.3187001283707407,
            "count": 20
        },
        "Movement.Policy.CuriosityReward.sum": {
            "value": 15.33909685909748,
            "min": 5.588870905863587,
            "max": 21.060453159268945,
            "count": 20
        },
        "Movement.Losses.PolicyLoss.mean": {
            "value": 0.24606410863956574,
            "min": 0.2362714157318057,
            "max": 0.25650560631133984,
            "count": 20
        },
        "Movement.Losses.PolicyLoss.sum": {
            "value": 8.858307911024367,
            "min": 5.130112126226797,
            "max": 9.31924253083419,
            "count": 20
        },
        "Movement.Losses.ValueLoss.mean": {
            "value": 0.014324394940289075,
            "min": 0.0009493745165310918,
            "max": 0.016368122395246112,
            "count": 20
        },
        "Movement.Losses.ValueLoss.sum": {
            "value": 0.5156782178504067,
            "min": 0.03322810807858821,
            "max": 0.5156782178504067,
            "count": 20
        },
        "Movement.Policy.LearningRate.mean": {
            "value": 7.49951416686111e-06,
            "min": 7.49951416686111e-06,
            "max": 0.00028994925335025,
            "count": 20
        },
        "Movement.Policy.LearningRate.sum": {
            "value": 0.00026998251000699995,
            "min": 0.00026998251000699995,
            "max": 0.009712119462627,
            "count": 20
        },
        "Movement.Policy.Epsilon.mean": {
            "value": 0.10249980555555555,
            "min": 0.10249980555555555,
            "max": 0.19664975,
            "count": 20
        },
        "Movement.Policy.Epsilon.sum": {
            "value": 3.689993,
            "min": 3.689993,
            "max": 6.937373,
            "count": 20
        },
        "Movement.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005000000000000001,
            "count": 20
        },
        "Movement.Policy.Beta.sum": {
            "value": 0.018000000000000002,
            "min": 0.010000000000000002,
            "max": 0.019000000000000003,
            "count": 20
        },
        "Movement.Losses.CuriosityForwardLoss.mean": {
            "value": 0.11782809276010744,
            "min": 0.037195971485280144,
            "max": 0.13757060190868295,
            "count": 20
        },
        "Movement.Losses.CuriosityForwardLoss.sum": {
            "value": 4.241811339363868,
            "min": 1.3390549734700852,
            "max": 4.952541668712586,
            "count": 20
        },
        "Movement.Losses.CuriosityInverseLoss.mean": {
            "value": 1.2175381333479265,
            "min": 0.9110680066843089,
            "max": 1.905139295407364,
            "count": 20
        },
        "Movement.Losses.CuriosityInverseLoss.sum": {
            "value": 43.83137280052535,
            "min": 33.70951624731943,
            "max": 66.93410873486386,
            "count": 20
        },
        "Movement.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "Movement.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1683564569",
        "python_version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]",
        "command_line_arguments": "D:\\University\\Honours\\Testing\\MLAgents Testing2\\venv\\Scripts\\mlagents-learn config/Movement.yaml --initialize-from=ConMovement1 --run-id=ConMovement_Walls1",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1683564962"
    },
    "total": 393.3751681,
    "count": 1,
    "self": 0.007598400000006222,
    "children": {
        "run_training.setup": {
            "total": 0.06701520000000005,
            "count": 1,
            "self": 0.06701520000000005
        },
        "TrainerController.start_learning": {
            "total": 393.3005545,
            "count": 1,
            "self": 0.08600080000127264,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.5950846,
                    "count": 1,
                    "self": 5.5950846
                },
                "TrainerController.advance": {
                    "total": 387.5671706999987,
                    "count": 5272,
                    "self": 0.0742056999992542,
                    "children": {
                        "env_step": {
                            "total": 38.66081819999941,
                            "count": 5272,
                            "self": 32.13396519999839,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 6.481464400000893,
                                    "count": 5272,
                                    "self": 0.2633265000010736,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 6.218137899999819,
                                            "count": 5031,
                                            "self": 3.014166999999599,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3.20397090000022,
                                                    "count": 5031,
                                                    "self": 3.20397090000022
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.0453886000001269,
                                    "count": 5272,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 388.4595702000006,
                                            "count": 5272,
                                            "is_parallel": true,
                                            "self": 361.33345720000005,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.000644000000000311,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00019200000000019202,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.000452000000000119,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.000452000000000119
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 27.12546900000055,
                                                    "count": 5272,
                                                    "is_parallel": true,
                                                    "self": 0.6182249000020832,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.9393179000001934,
                                                            "count": 5272,
                                                            "is_parallel": true,
                                                            "self": 0.9393179000001934
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 23.90682369999996,
                                                            "count": 5272,
                                                            "is_parallel": true,
                                                            "self": 23.90682369999996
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1.661102499998309,
                                                            "count": 5272,
                                                            "is_parallel": true,
                                                            "self": 0.4572813999960115,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.2038211000022976,
                                                                    "count": 10544,
                                                                    "is_parallel": true,
                                                                    "self": 1.2038211000022976
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 348.83214680000003,
                            "count": 5272,
                            "self": 0.15135939999873926,
                            "children": {
                                "process_trajectory": {
                                    "total": 7.846563700000631,
                                    "count": 5272,
                                    "self": 7.846563700000631
                                },
                                "_update_policy": {
                                    "total": 340.8342237000007,
                                    "count": 698,
                                    "self": 12.41874199999819,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 328.4154817000025,
                                            "count": 28665,
                                            "self": 328.4154817000025
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.999999643790943e-07,
                    "count": 1,
                    "self": 5.999999643790943e-07
                },
                "TrainerController._save_models": {
                    "total": 0.05229780000001938,
                    "count": 1,
                    "self": 0.006878200000016932,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04541960000000245,
                            "count": 1,
                            "self": 0.04541960000000245
                        }
                    }
                }
            }
        }
    }
}